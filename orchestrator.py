"""Orchestrates experiments
"""
import json
import argparse
import logging
import coloredlogs
import multiprocessing
import glob
import os
import time

from os.path import exists as E
from os.path import join as J

import models
import models.utils
from models.utils.non_daemonic_pool import NonDaemonPool


import config as c


# Set up logging components

coloredlogs.install(level=logging.DEBUG)

logger = logging.getLogger(__name__)

from exp_runner import run_experiment



def parse_args():
    parser = argparse.ArgumentParser(
        description=(
            'The experiment orchestrator. This takes as argument a'
            ' directory containing experiment specifications and '
            'the desired parallelism with which to run the experiment.'))

    parser.add_argument('specification_dir', type=str,
        help='A directory containing experiment specifications '
             'generated by specifier.py')

    parser.add_argument('out_dir', type=str, help='The output directory')

    parser.add_argument('--num_gpus', type=int, default=1, help='Number of GPUs to use')    

    parser.add_argument('--exps_per_gpu', type=int, default=1, help='Number of examples per GPU')

    return parser.parse_args()


def load_specifications(specification_dir):
    """Loads experiment specifications from a specified directory.
    
    Args:
        specification_dir (str): The specified directory containing experiment specifications.
    
    Returns:
        list(dict): A list of experiment specification JSONs.
    """
    assert E(specification_dir), "Specification directory {} does not exist".format(specification_dir)

    specification_jsons =  glob.glob(J(specification_dir, '*.json'))

    logger.info("Loading experiment specificaitons...")
    if not specification_jsons:
        logger.warning("Could not find any experiment specifications in {}".format(specification_dir))

    specs = []
    for spec_path in specification_jsons:
        with open(spec_path, 'r') as f:
            specs.append(json.load(f))
    logger.info("Found {} experiment specifications".format(len(specs)))

    return specs


def launch_experiment_on_device(args):
    """Launches an experiment on a particular device
    
    Args:
        args (tuple): The arguments for the experiment
    """
    run_exp_args = args[:-1]
    available_devices = args[-1]
    spec = args[0]

    # Get an available GPU device 
    gpu_id = available_devices.get()
    old_visible_devices = os.environ.get(c.CVISIBLE, "")
    os.environ[c.CVISIBLE] = str(gpu_id)

    # Launch the experiment
    try:
        logger.info("Running experiment {} on GPU {}".format(spec["name"], gpu_id))
        proc = multiprocessing.Process(target=run_experiment, args=run_exp_args)
        proc.start()
        proc.join()

        logger.info("Experiment {} completed sucessfully".format(spec["name"]))

    finally:
        # Return the GPU toekn back to the queue.
        os.environ[c.CVISIBLE] = old_visible_devices
        available_devices.put(gpu_id)


def main(specification_dir, out_dir, num_gpus, exps_per_gpu):
    """Run the experiment orchestrator
    """

    # 1. Load the specifications
    specs = load_specifications(specification_dir)
    
    # 2. Create the output directory
    if not os.path.exists(out_dir):
        os.makedirs(out_dir)
    
    if os.listdir(out_dir):
        logger.warning("The output directory {} is not empty. Are you sure you want to continue?".format(out_dir))
        # time.sleep(3)

    # 3. Create the workers with specific environment variables
    num_workers = num_gpus * exps_per_gpu

    with NonDaemonPool(num_workers) as pool:
        logger.info("Created {} workers".format(num_workers))
        
        # Create the available device queue.
        m = multiprocessing.Manager()
        available_devices =  m.Queue()
        for g in range(num_gpus):
            for _ in range(exps_per_gpu):
                available_devices.put(g)


        # 4. Create and distribute the workload
        workload = [
            (spec, J(out_dir, spec["name"]), available_devices) for spec in specs
        ]
        logger.info("Running {} jobs accross {} GPUs".format(len(workload), num_gpus))

        # 5. Launch the workers.
        logger.info("Launching the workers using `run_experiment`.")
        list(pool.imap_unordered(
            launch_experiment_on_device,
            workload
        ))
        # pool.join()
    
    logger.info("Success, all experiments completed!")
        
    


if __name__ == '__main__':
    args = parse_args()
    main(args.specification_dir, args.out_dir, args.num_gpus, args.exps_per_gpu)